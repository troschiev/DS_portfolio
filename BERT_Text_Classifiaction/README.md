# Идентификация токсичных комментариев

## Описание

Проект посвящен созданию модели, определяющей токсичные комментарии к правкам википедии. 
Задача - классификация. 
Целевая метрика - F1.

## Инструменты

Загрузка, хранение и обработка данных: pandas, pytorch dataset/dataloader, numpy

Визуализация: seaborn, matplotlib, wordcloud

Автоматизация: sklearn pipeline, optuna

Модели: sklearn logistic regression & naive Bayes, catboost, BERT (Hugging Face)

Работа с текстом: nltk, enchant, spacy, gensim

Индивидуальные решения:
- "мягкая" очистка текста для работы BERT
- борьба с дисбалансом: веса классов в функции потерь, подстройка порога классификации на валидационной выборке

## Данные

Использован датасет Я.Практикума:
- 160 000 размеченных записей на английском языке
- дисбаланс классов 9 к 1

## Выводы

- лучший результат с большим отрывом у fine-tuned BERT классификатора, обученного в течение всего лишь 2 эпох с малым LR
- второй результат - у логистической регрессии на TF-IDF признаках после лемматизации текста